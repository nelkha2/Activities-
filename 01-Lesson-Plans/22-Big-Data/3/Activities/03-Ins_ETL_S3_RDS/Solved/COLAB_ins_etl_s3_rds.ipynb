{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EczuELbux9bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iESyx7xlx-qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_pmGKkNx2t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-2.4.4-bin-hadoop2.7\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark import SparkFiles\n",
        "# Load in user_data.csv from S3 into a DataFrame\n",
        "url = \"https://s3.amazonaws.com//<bucket name>/user_data.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "user_data_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"user_data.csv\"), inferSchema=True, sep=',')\n",
        "user_data_df.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1V0g4bwyB4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in user_payment.csv from S3 into a DataFrame\n",
        "\n",
        "url = \"https://s3.amazonaws.com//<bucket name>/user_payment.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "user_payment_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"user_payment.csv\"), inferSchema=True, sep=',')\n",
        "user_payment_df.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dreCK_9pyJLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join the two DataFrame\n",
        "joined_df= user_data_df.join(user_payment_df, on=\"username\", how=\"inner\")\n",
        "joined_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax6KkbULyMBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop null values\n",
        "dropna_df = joined_df.dropna()\n",
        "dropna_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezkuF3sfyOmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in a sql function to use columns\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Filter for only columns with active users\n",
        "cleaned_df = dropna_df.filter(col(\"active_user\")  == True)\n",
        "cleaned_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKZEaxkFyRd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create user dataframe to match active_user table\n",
        "clean_user_df = cleaned_df.select([\"id\", \"first_name\", \"last_name\", \"username\"])\n",
        "clean_user_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbfvmoQ5ybDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create user dataframe to match billing_info table\n",
        "clean_billing_df = cleaned_df.select([\"billing_id\", \"street_address\", \"state\", \"username\"])\n",
        "clean_billing_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsYy9OyOyeWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql:/<endpoint>:5432/my_data_class_db\"\n",
        "config = {\"user\":\"root\", \n",
        "          \"password\": \"<password>\", \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSoBkf5WygPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append DataFrame to active_user table in RDS\n",
        "\n",
        "clean_user_df.write.jdbc(url=jdbc_url, table='active_user', mode=mode, properties=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2hfVrP3yhgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write dataframe to billing_info table in RDS\n",
        "\n",
        "clean_billing_df.write.jdbc(url=jdbc_url, table='billing_info', mode=mode, properties=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5nF0Y1Iym2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write dataframe to payment_info table in RDS\n",
        "\n",
        "clean_payment_df.write.jdbc(url=jdbc_url, table='payment_info', mode=mode, properties=config)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}